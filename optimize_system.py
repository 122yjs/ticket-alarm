#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
í‹°ì¼“ ì•Œë¦¼ ì‹œìŠ¤í…œ ì„±ëŠ¥ ìµœì í™” ë„êµ¬
ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰ì„ ë¶„ì„í•˜ê³  ì„±ëŠ¥ì„ ìµœì í™”í•©ë‹ˆë‹¤.
"""

import os
import sys
import json
import psutil
import sqlite3
import argparse
import subprocess
import time
import gc
import threading
from datetime import datetime, timedelta
from pathlib import Path
import logging
import requests
from collections import defaultdict, deque
import signal

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('logs/optimization.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class SystemOptimizer:
    """ì‹œìŠ¤í…œ ìµœì í™” í´ë˜ìŠ¤"""
    
    def __init__(self, config_file='config.json'):
        self.config = self.load_config(config_file)
        self.db_path = 'optimization.db'
        self.init_database()
        
        # ìµœì í™” ì„ê³„ê°’
        self.thresholds = {
            'cpu_usage': 80.0,
            'memory_usage': 85.0,
            'disk_usage': 90.0,
            'disk_io_wait': 20.0,
            'network_latency': 1000,  # ms
            'response_time': 5000,    # ms
            'error_rate': 5.0,        # %
            'log_file_size': 100 * 1024 * 1024,  # 100MB
            'db_size': 500 * 1024 * 1024,        # 500MB
        }
        
        # ì„±ëŠ¥ ë©”íŠ¸ë¦­ íˆìŠ¤í† ë¦¬
        self.metrics_history = {
            'cpu': deque(maxlen=60),
            'memory': deque(maxlen=60),
            'disk_io': deque(maxlen=60),
            'network': deque(maxlen=60),
            'response_time': deque(maxlen=60)
        }
        
        # ìµœì í™” ì‘ì—…
        self.optimization_tasks = {
            'memory_cleanup': self.optimize_memory,
            'disk_cleanup': self.optimize_disk,
            'log_rotation': self.optimize_logs,
            'database_optimization': self.optimize_database,
            'process_optimization': self.optimize_processes,
            'network_optimization': self.optimize_network,
            'cache_optimization': self.optimize_cache,
            'system_tuning': self.optimize_system_settings
        }
        
        self.running = False
        self.monitor_thread = None
    
    def load_config(self, config_file):
        """ì„¤ì • íŒŒì¼ ë¡œë“œ"""
        try:
            with open(config_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            logger.error(f"ì„¤ì • íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return {}
    
    def init_database(self):
        """ìµœì í™” ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # ì„±ëŠ¥ ë©”íŠ¸ë¦­ í…Œì´ë¸”
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS performance_metrics (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
                    metric_type TEXT,
                    value REAL,
                    threshold REAL,
                    status TEXT,
                    details TEXT
                )
            ''')
            
            # ìµœì í™” ì‘ì—… í…Œì´ë¸”
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS optimization_tasks (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
                    task_type TEXT,
                    status TEXT,
                    before_value REAL,
                    after_value REAL,
                    improvement REAL,
                    details TEXT,
                    duration REAL
                )
            ''')
            
            # ì‹œìŠ¤í…œ ìƒíƒœ í…Œì´ë¸”
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS system_status (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
                    cpu_usage REAL,
                    memory_usage REAL,
                    disk_usage REAL,
                    disk_io_read REAL,
                    disk_io_write REAL,
                    network_sent REAL,
                    network_recv REAL,
                    process_count INTEGER,
                    load_average REAL
                )
            ''')
            
            conn.commit()
            conn.close()
            
            logger.info("ìµœì í™” ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ")
            
        except Exception as e:
            logger.error(f"ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    
    def collect_system_metrics(self):
        """ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­ ìˆ˜ì§‘"""
        try:
            # CPU ì‚¬ìš©ë¥ 
            cpu_percent = psutil.cpu_percent(interval=1)
            
            # ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ 
            memory = psutil.virtual_memory()
            memory_percent = memory.percent
            
            # ë””ìŠ¤í¬ ì‚¬ìš©ë¥ 
            disk = psutil.disk_usage('/')
            disk_percent = (disk.used / disk.total) * 100
            
            # ë””ìŠ¤í¬ I/O
            disk_io = psutil.disk_io_counters()
            
            # ë„¤íŠ¸ì›Œí¬ I/O
            network_io = psutil.net_io_counters()
            
            # í”„ë¡œì„¸ìŠ¤ ìˆ˜
            process_count = len(psutil.pids())
            
            # ë¡œë“œ í‰ê·  (Linux/macOS)
            try:
                load_avg = os.getloadavg()[0]
            except (OSError, AttributeError):
                load_avg = 0.0
            
            metrics = {
                'timestamp': datetime.now(),
                'cpu_usage': cpu_percent,
                'memory_usage': memory_percent,
                'disk_usage': disk_percent,
                'disk_io_read': disk_io.read_bytes if disk_io else 0,
                'disk_io_write': disk_io.write_bytes if disk_io else 0,
                'network_sent': network_io.bytes_sent if network_io else 0,
                'network_recv': network_io.bytes_recv if network_io else 0,
                'process_count': process_count,
                'load_average': load_avg
            }
            
            # íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
            self.metrics_history['cpu'].append(cpu_percent)
            self.metrics_history['memory'].append(memory_percent)
            
            return metrics
            
        except Exception as e:
            logger.error(f"ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            return None
    
    def save_metrics(self, metrics):
        """ë©”íŠ¸ë¦­ì„ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            cursor.execute('''
                INSERT INTO system_status (
                    cpu_usage, memory_usage, disk_usage,
                    disk_io_read, disk_io_write,
                    network_sent, network_recv,
                    process_count, load_average
                ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
            ''', (
                metrics['cpu_usage'],
                metrics['memory_usage'],
                metrics['disk_usage'],
                metrics['disk_io_read'],
                metrics['disk_io_write'],
                metrics['network_sent'],
                metrics['network_recv'],
                metrics['process_count'],
                metrics['load_average']
            ))
            
            conn.commit()
            conn.close()
            
        except Exception as e:
            logger.error(f"ë©”íŠ¸ë¦­ ì €ì¥ ì‹¤íŒ¨: {e}")
    
    def analyze_performance_issues(self, metrics):
        """ì„±ëŠ¥ ì´ìŠˆ ë¶„ì„"""
        issues = []
        
        # CPU ì‚¬ìš©ë¥  í™•ì¸
        if metrics['cpu_usage'] > self.thresholds['cpu_usage']:
            issues.append({
                'type': 'cpu_high',
                'severity': 'HIGH',
                'message': f"CPU ì‚¬ìš©ë¥ ì´ ë†’ìŠµë‹ˆë‹¤: {metrics['cpu_usage']:.1f}%",
                'value': metrics['cpu_usage'],
                'threshold': self.thresholds['cpu_usage'],
                'recommendation': 'CPU ì§‘ì•½ì ì¸ í”„ë¡œì„¸ìŠ¤ë¥¼ í™•ì¸í•˜ê³  ìµœì í™”í•˜ì„¸ìš”'
            })
        
        # ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  í™•ì¸
        if metrics['memory_usage'] > self.thresholds['memory_usage']:
            issues.append({
                'type': 'memory_high',
                'severity': 'HIGH',
                'message': f"ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ ì´ ë†’ìŠµë‹ˆë‹¤: {metrics['memory_usage']:.1f}%",
                'value': metrics['memory_usage'],
                'threshold': self.thresholds['memory_usage'],
                'recommendation': 'ë©”ëª¨ë¦¬ ì •ë¦¬ ë° ìºì‹œ ìµœì í™”ë¥¼ ìˆ˜í–‰í•˜ì„¸ìš”'
            })
        
        # ë””ìŠ¤í¬ ì‚¬ìš©ë¥  í™•ì¸
        if metrics['disk_usage'] > self.thresholds['disk_usage']:
            issues.append({
                'type': 'disk_high',
                'severity': 'CRITICAL',
                'message': f"ë””ìŠ¤í¬ ì‚¬ìš©ë¥ ì´ ë†’ìŠµë‹ˆë‹¤: {metrics['disk_usage']:.1f}%",
                'value': metrics['disk_usage'],
                'threshold': self.thresholds['disk_usage'],
                'recommendation': 'ë¶ˆí•„ìš”í•œ íŒŒì¼ì„ ì‚­ì œí•˜ê³  ë¡œê·¸ë¥¼ ì •ë¦¬í•˜ì„¸ìš”'
            })
        
        # ë¡œë“œ í‰ê·  í™•ì¸
        cpu_count = psutil.cpu_count()
        if metrics['load_average'] > cpu_count * 2:
            issues.append({
                'type': 'load_high',
                'severity': 'HIGH',
                'message': f"ì‹œìŠ¤í…œ ë¡œë“œê°€ ë†’ìŠµë‹ˆë‹¤: {metrics['load_average']:.2f}",
                'value': metrics['load_average'],
                'threshold': cpu_count * 2,
                'recommendation': 'ì‹¤í–‰ ì¤‘ì¸ í”„ë¡œì„¸ìŠ¤ë¥¼ í™•ì¸í•˜ê³  ë¶ˆí•„ìš”í•œ ì‘ì—…ì„ ì¤‘ë‹¨í•˜ì„¸ìš”'
            })
        
        # íŠ¸ë Œë“œ ë¶„ì„
        if len(self.metrics_history['cpu']) >= 10:
            recent_cpu = list(self.metrics_history['cpu'])[-10:]
            if all(cpu > self.thresholds['cpu_usage'] * 0.8 for cpu in recent_cpu):
                issues.append({
                    'type': 'cpu_trend',
                    'severity': 'MEDIUM',
                    'message': "CPU ì‚¬ìš©ë¥ ì´ ì§€ì†ì ìœ¼ë¡œ ë†’ìŠµë‹ˆë‹¤",
                    'value': sum(recent_cpu) / len(recent_cpu),
                    'threshold': self.thresholds['cpu_usage'] * 0.8,
                    'recommendation': 'ì‹œìŠ¤í…œ ìµœì í™”ë¥¼ ê³ ë ¤í•˜ì„¸ìš”'
                })
        
        return issues
    
    def optimize_memory(self):
        """ë©”ëª¨ë¦¬ ìµœì í™”"""
        start_time = time.time()
        
        try:
            # ì‹œì‘ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰
            memory_before = psutil.virtual_memory().percent
            
            optimizations = []
            
            # Python ê°€ë¹„ì§€ ì»¬ë ‰ì…˜
            collected = gc.collect()
            if collected > 0:
                optimizations.append(f"ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ìœ¼ë¡œ {collected}ê°œ ê°ì²´ ì •ë¦¬")
            
            # ì‹œìŠ¤í…œ ìºì‹œ ì •ë¦¬ (Linux)
            try:
                if os.path.exists('/proc/sys/vm/drop_caches'):
                    subprocess.run(['sudo', 'sync'], check=True, timeout=10)
                    subprocess.run(
                        ['sudo', 'sh', '-c', 'echo 1 > /proc/sys/vm/drop_caches'],
                        check=True, timeout=10
                    )
                    optimizations.append("ì‹œìŠ¤í…œ í˜ì´ì§€ ìºì‹œ ì •ë¦¬")
            except (subprocess.CalledProcessError, subprocess.TimeoutExpired):
                pass
            
            # ìŠ¤ì™‘ ì‚¬ìš©ëŸ‰ í™•ì¸ ë° ìµœì í™”
            swap = psutil.swap_memory()
            if swap.percent > 50:
                try:
                    subprocess.run(['sudo', 'swapoff', '-a'], check=True, timeout=30)
                    subprocess.run(['sudo', 'swapon', '-a'], check=True, timeout=30)
                    optimizations.append("ìŠ¤ì™‘ ë©”ëª¨ë¦¬ ìµœì í™”")
                except (subprocess.CalledProcessError, subprocess.TimeoutExpired):
                    pass
            
            # ì¢…ë£Œ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰
            memory_after = psutil.virtual_memory().percent
            improvement = memory_before - memory_after
            
            duration = time.time() - start_time
            
            result = {
                'status': 'SUCCESS',
                'before_value': memory_before,
                'after_value': memory_after,
                'improvement': improvement,
                'details': '; '.join(optimizations) if optimizations else 'ìµœì í™” ì‘ì—… ì—†ìŒ',
                'duration': duration
            }
            
            logger.info(f"ë©”ëª¨ë¦¬ ìµœì í™” ì™„ë£Œ: {memory_before:.1f}% â†’ {memory_after:.1f}% ({improvement:+.1f}%)")
            return result
            
        except Exception as e:
            logger.error(f"ë©”ëª¨ë¦¬ ìµœì í™” ì‹¤íŒ¨: {e}")
            return {
                'status': 'ERROR',
                'before_value': 0,
                'after_value': 0,
                'improvement': 0,
                'details': f"ì˜¤ë¥˜: {e}",
                'duration': time.time() - start_time
            }
    
    def optimize_disk(self):
        """ë””ìŠ¤í¬ ìµœì í™”"""
        start_time = time.time()
        
        try:
            # ì‹œì‘ ë””ìŠ¤í¬ ì‚¬ìš©ëŸ‰
            disk_before = psutil.disk_usage('/').percent
            
            optimizations = []
            freed_space = 0
            
            # ì„ì‹œ íŒŒì¼ ì •ë¦¬
            temp_dirs = ['/tmp', '/var/tmp', 'temp', 'tmp']
            for temp_dir in temp_dirs:
                if os.path.exists(temp_dir):
                    try:
                        for root, dirs, files in os.walk(temp_dir):
                            for file in files:
                                file_path = os.path.join(root, file)
                                try:
                                    # 1ì¼ ì´ìƒ ëœ ì„ì‹œ íŒŒì¼ ì‚­ì œ
                                    if os.path.getmtime(file_path) < time.time() - 86400:
                                        file_size = os.path.getsize(file_path)
                                        os.remove(file_path)
                                        freed_space += file_size
                                except (OSError, PermissionError):
                                    pass
                        if freed_space > 0:
                            optimizations.append(f"{temp_dir}ì—ì„œ {freed_space // 1024 // 1024}MB ì •ë¦¬")
                    except Exception:
                        pass
            
            # ë¡œê·¸ íŒŒì¼ ì••ì¶•
            log_dir = 'logs'
            if os.path.exists(log_dir):
                try:
                    import gzip
                    import shutil
                    
                    for log_file in os.listdir(log_dir):
                        if log_file.endswith('.log'):
                            log_path = os.path.join(log_dir, log_file)
                            log_stat = os.stat(log_path)
                            
                            # 1ì¼ ì´ìƒ ëœ ë¡œê·¸ íŒŒì¼ì´ê³  10MB ì´ìƒì¸ ê²½ìš° ì••ì¶•
                            if (log_stat.st_mtime < time.time() - 86400 and 
                                log_stat.st_size > 10 * 1024 * 1024):
                                
                                compressed_path = log_path + '.gz'
                                with open(log_path, 'rb') as f_in:
                                    with gzip.open(compressed_path, 'wb') as f_out:
                                        shutil.copyfileobj(f_in, f_out)
                                
                                original_size = log_stat.st_size
                                compressed_size = os.path.getsize(compressed_path)
                                
                                os.remove(log_path)
                                freed_space += original_size - compressed_size
                                optimizations.append(f"{log_file} ì••ì¶• ({original_size // 1024 // 1024}MB â†’ {compressed_size // 1024 // 1024}MB)")
                                
                except Exception as e:
                    logger.warning(f"ë¡œê·¸ ì••ì¶• ì‹¤íŒ¨: {e}")
            
            # íŒ¨í‚¤ì§€ ìºì‹œ ì •ë¦¬
            try:
                result = subprocess.run(
                    ['pip', 'cache', 'purge'],
                    capture_output=True,
                    text=True,
                    timeout=30
                )
                if result.returncode == 0:
                    optimizations.append("pip ìºì‹œ ì •ë¦¬")
            except (subprocess.TimeoutExpired, FileNotFoundError):
                pass
            
            # APT ìºì‹œ ì •ë¦¬ (Ubuntu/Debian)
            try:
                subprocess.run(['sudo', 'apt', 'clean'], check=True, timeout=30)
                subprocess.run(['sudo', 'apt', 'autoremove', '-y'], check=True, timeout=60)
                optimizations.append("APT ìºì‹œ ë° ë¶ˆí•„ìš”í•œ íŒ¨í‚¤ì§€ ì •ë¦¬")
            except (subprocess.CalledProcessError, subprocess.TimeoutExpired, FileNotFoundError):
                pass
            
            # ì¢…ë£Œ ë””ìŠ¤í¬ ì‚¬ìš©ëŸ‰
            disk_after = psutil.disk_usage('/').percent
            improvement = disk_before - disk_after
            
            duration = time.time() - start_time
            
            result = {
                'status': 'SUCCESS',
                'before_value': disk_before,
                'after_value': disk_after,
                'improvement': improvement,
                'details': '; '.join(optimizations) if optimizations else 'ìµœì í™” ì‘ì—… ì—†ìŒ',
                'duration': duration
            }
            
            logger.info(f"ë””ìŠ¤í¬ ìµœì í™” ì™„ë£Œ: {disk_before:.1f}% â†’ {disk_after:.1f}% ({improvement:+.1f}%)")
            return result
            
        except Exception as e:
            logger.error(f"ë””ìŠ¤í¬ ìµœì í™” ì‹¤íŒ¨: {e}")
            return {
                'status': 'ERROR',
                'before_value': 0,
                'after_value': 0,
                'improvement': 0,
                'details': f"ì˜¤ë¥˜: {e}",
                'duration': time.time() - start_time
            }
    
    def optimize_logs(self):
        """ë¡œê·¸ ìµœì í™”"""
        start_time = time.time()
        
        try:
            log_dir = 'logs'
            if not os.path.exists(log_dir):
                return {
                    'status': 'SKIP',
                    'before_value': 0,
                    'after_value': 0,
                    'improvement': 0,
                    'details': 'ë¡œê·¸ ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŒ',
                    'duration': time.time() - start_time
                }
            
            # ì‹œì‘ ë¡œê·¸ í¬ê¸°
            total_size_before = 0
            for root, dirs, files in os.walk(log_dir):
                for file in files:
                    total_size_before += os.path.getsize(os.path.join(root, file))
            
            optimizations = []
            
            # ì˜¤ë˜ëœ ë¡œê·¸ íŒŒì¼ ì‚­ì œ
            cutoff_time = time.time() - (30 * 24 * 3600)  # 30ì¼
            deleted_files = 0
            
            for root, dirs, files in os.walk(log_dir):
                for file in files:
                    file_path = os.path.join(root, file)
                    try:
                        if os.path.getmtime(file_path) < cutoff_time:
                            os.remove(file_path)
                            deleted_files += 1
                    except (OSError, PermissionError):
                        pass
            
            if deleted_files > 0:
                optimizations.append(f"{deleted_files}ê°œ ì˜¤ë˜ëœ ë¡œê·¸ íŒŒì¼ ì‚­ì œ")
            
            # í° ë¡œê·¸ íŒŒì¼ ë¶„í• 
            max_size = 50 * 1024 * 1024  # 50MB
            split_files = 0
            
            for root, dirs, files in os.walk(log_dir):
                for file in files:
                    if file.endswith('.log'):
                        file_path = os.path.join(root, file)
                        try:
                            if os.path.getsize(file_path) > max_size:
                                # íŒŒì¼ì„ ë¶„í•  (ê°„ë‹¨í•œ ë°©ë²•: ë’¤ìª½ ì ˆë°˜ë§Œ ìœ ì§€)
                                with open(file_path, 'r', encoding='utf-8') as f:
                                    lines = f.readlines()
                                
                                half_point = len(lines) // 2
                                with open(file_path, 'w', encoding='utf-8') as f:
                                    f.writelines(lines[half_point:])
                                
                                split_files += 1
                        except (OSError, PermissionError, UnicodeDecodeError):
                            pass
            
            if split_files > 0:
                optimizations.append(f"{split_files}ê°œ í° ë¡œê·¸ íŒŒì¼ ë¶„í• ")
            
            # ì¢…ë£Œ ë¡œê·¸ í¬ê¸°
            total_size_after = 0
            for root, dirs, files in os.walk(log_dir):
                for file in files:
                    try:
                        total_size_after += os.path.getsize(os.path.join(root, file))
                    except OSError:
                        pass
            
            improvement = (total_size_before - total_size_after) / 1024 / 1024  # MB
            duration = time.time() - start_time
            
            result = {
                'status': 'SUCCESS',
                'before_value': total_size_before / 1024 / 1024,
                'after_value': total_size_after / 1024 / 1024,
                'improvement': improvement,
                'details': '; '.join(optimizations) if optimizations else 'ìµœì í™” ì‘ì—… ì—†ìŒ',
                'duration': duration
            }
            
            logger.info(f"ë¡œê·¸ ìµœì í™” ì™„ë£Œ: {total_size_before/1024/1024:.1f}MB â†’ {total_size_after/1024/1024:.1f}MB ({improvement:+.1f}MB)")
            return result
            
        except Exception as e:
            logger.error(f"ë¡œê·¸ ìµœì í™” ì‹¤íŒ¨: {e}")
            return {
                'status': 'ERROR',
                'before_value': 0,
                'after_value': 0,
                'improvement': 0,
                'details': f"ì˜¤ë¥˜: {e}",
                'duration': time.time() - start_time
            }
    
    def optimize_database(self):
        """ë°ì´í„°ë² ì´ìŠ¤ ìµœì í™”"""
        start_time = time.time()
        
        try:
            db_files = ['performance.db', 'security_audit.db', 'optimization.db']
            optimizations = []
            total_size_before = 0
            total_size_after = 0
            
            for db_file in db_files:
                if os.path.exists(db_file):
                    size_before = os.path.getsize(db_file)
                    total_size_before += size_before
                    
                    try:
                        conn = sqlite3.connect(db_file)
                        cursor = conn.cursor()
                        
                        # VACUUMìœ¼ë¡œ ë°ì´í„°ë² ì´ìŠ¤ ìµœì í™”
                        cursor.execute('VACUUM')
                        
                        # ì˜¤ë˜ëœ ë°ì´í„° ì •ë¦¬ (30ì¼ ì´ìƒ)
                        cutoff_date = (datetime.now() - timedelta(days=30)).isoformat()
                        
                        # í…Œì´ë¸”ë³„ ì •ë¦¬
                        tables_to_clean = [
                            'performance_metrics',
                            'security_checks',
                            'system_status',
                            'optimization_tasks'
                        ]
                        
                        deleted_rows = 0
                        for table in tables_to_clean:
                            try:
                                cursor.execute(f'''
                                    DELETE FROM {table} 
                                    WHERE timestamp < ?
                                ''', (cutoff_date,))
                                deleted_rows += cursor.rowcount
                            except sqlite3.OperationalError:
                                # í…Œì´ë¸”ì´ ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ê²½ìš°
                                pass
                        
                        conn.commit()
                        conn.close()
                        
                        size_after = os.path.getsize(db_file)
                        total_size_after += size_after
                        
                        if deleted_rows > 0 or size_after < size_before:
                            optimizations.append(f"{db_file}: {deleted_rows}í–‰ ì‚­ì œ, {(size_before-size_after)/1024/1024:.1f}MB ì ˆì•½")
                        
                    except Exception as e:
                        logger.warning(f"{db_file} ìµœì í™” ì‹¤íŒ¨: {e}")
                        total_size_after += size_before
            
            improvement = (total_size_before - total_size_after) / 1024 / 1024  # MB
            duration = time.time() - start_time
            
            result = {
                'status': 'SUCCESS',
                'before_value': total_size_before / 1024 / 1024,
                'after_value': total_size_after / 1024 / 1024,
                'improvement': improvement,
                'details': '; '.join(optimizations) if optimizations else 'ìµœì í™” ì‘ì—… ì—†ìŒ',
                'duration': duration
            }
            
            logger.info(f"ë°ì´í„°ë² ì´ìŠ¤ ìµœì í™” ì™„ë£Œ: {total_size_before/1024/1024:.1f}MB â†’ {total_size_after/1024/1024:.1f}MB ({improvement:+.1f}MB)")
            return result
            
        except Exception as e:
            logger.error(f"ë°ì´í„°ë² ì´ìŠ¤ ìµœì í™” ì‹¤íŒ¨: {e}")
            return {
                'status': 'ERROR',
                'before_value': 0,
                'after_value': 0,
                'improvement': 0,
                'details': f"ì˜¤ë¥˜: {e}",
                'duration': time.time() - start_time
            }
    
    def optimize_processes(self):
        """í”„ë¡œì„¸ìŠ¤ ìµœì í™”"""
        start_time = time.time()
        
        try:
            # ì‹œì‘ í”„ë¡œì„¸ìŠ¤ ìˆ˜
            processes_before = len(psutil.pids())
            
            optimizations = []
            terminated_processes = 0
            
            # ë†’ì€ CPU/ë©”ëª¨ë¦¬ ì‚¬ìš© í”„ë¡œì„¸ìŠ¤ í™•ì¸
            high_usage_processes = []
            
            for proc in psutil.process_iter(['pid', 'name', 'cpu_percent', 'memory_percent']):
                try:
                    proc_info = proc.info
                    if (proc_info['cpu_percent'] > 50 or proc_info['memory_percent'] > 20):
                        # ì‹œìŠ¤í…œ ì¤‘ìš” í”„ë¡œì„¸ìŠ¤ëŠ” ì œì™¸
                        if proc_info['name'] not in ['systemd', 'kernel', 'init', 'python3']:
                            high_usage_processes.append(proc_info)
                except (psutil.NoSuchProcess, psutil.AccessDenied):
                    pass
            
            if high_usage_processes:
                optimizations.append(f"{len(high_usage_processes)}ê°œ ê³ ì‚¬ìš©ëŸ‰ í”„ë¡œì„¸ìŠ¤ ë°œê²¬")
            
            # ì¢€ë¹„ í”„ë¡œì„¸ìŠ¤ ì •ë¦¬
            zombie_count = 0
            for proc in psutil.process_iter(['pid', 'status']):
                try:
                    if proc.info['status'] == psutil.STATUS_ZOMBIE:
                        zombie_count += 1
                except (psutil.NoSuchProcess, psutil.AccessDenied):
                    pass
            
            if zombie_count > 0:
                optimizations.append(f"{zombie_count}ê°œ ì¢€ë¹„ í”„ë¡œì„¸ìŠ¤ ë°œê²¬")
            
            # í”„ë¡œì„¸ìŠ¤ ìš°ì„ ìˆœìœ„ ì¡°ì • (í˜„ì¬ í”„ë¡œì„¸ìŠ¤)
            try:
                current_proc = psutil.Process()
                current_nice = current_proc.nice()
                if current_nice < 10:  # ìš°ì„ ìˆœìœ„ê°€ ë„ˆë¬´ ë†’ì€ ê²½ìš°
                    current_proc.nice(10)
                    optimizations.append("í˜„ì¬ í”„ë¡œì„¸ìŠ¤ ìš°ì„ ìˆœìœ„ ì¡°ì •")
            except (psutil.AccessDenied, psutil.NoSuchProcess):
                pass
            
            # ì¢…ë£Œ í”„ë¡œì„¸ìŠ¤ ìˆ˜
            processes_after = len(psutil.pids())
            improvement = processes_before - processes_after
            
            duration = time.time() - start_time
            
            result = {
                'status': 'SUCCESS',
                'before_value': processes_before,
                'after_value': processes_after,
                'improvement': improvement,
                'details': '; '.join(optimizations) if optimizations else 'ìµœì í™” ì‘ì—… ì—†ìŒ',
                'duration': duration
            }
            
            logger.info(f"í”„ë¡œì„¸ìŠ¤ ìµœì í™” ì™„ë£Œ: {processes_before}ê°œ â†’ {processes_after}ê°œ ({improvement:+d}ê°œ)")
            return result
            
        except Exception as e:
            logger.error(f"í”„ë¡œì„¸ìŠ¤ ìµœì í™” ì‹¤íŒ¨: {e}")
            return {
                'status': 'ERROR',
                'before_value': 0,
                'after_value': 0,
                'improvement': 0,
                'details': f"ì˜¤ë¥˜: {e}",
                'duration': time.time() - start_time
            }
    
    def optimize_network(self):
        """ë„¤íŠ¸ì›Œí¬ ìµœì í™”"""
        start_time = time.time()
        
        try:
            optimizations = []
            
            # ë„¤íŠ¸ì›Œí¬ ì—°ê²° ìƒíƒœ í™•ì¸
            connections = psutil.net_connections()
            established_count = len([c for c in connections if c.status == 'ESTABLISHED'])
            
            # DNS ìºì‹œ í”ŒëŸ¬ì‹œ (Windows)
            try:
                if os.name == 'nt':
                    subprocess.run(['ipconfig', '/flushdns'], check=True, timeout=10)
                    optimizations.append("DNS ìºì‹œ í”ŒëŸ¬ì‹œ")
            except (subprocess.CalledProcessError, subprocess.TimeoutExpired):
                pass
            
            # ë„¤íŠ¸ì›Œí¬ ì„¤ì • ìµœì í™” (Linux)
            try:
                if os.path.exists('/proc/sys/net/core/rmem_max'):
                    # TCP ë²„í¼ í¬ê¸° í™•ì¸
                    with open('/proc/sys/net/core/rmem_max', 'r') as f:
                        rmem_max = int(f.read().strip())
                    
                    if rmem_max < 16777216:  # 16MB
                        optimizations.append("TCP ìˆ˜ì‹  ë²„í¼ í¬ê¸° ìµœì í™” ê¶Œì¥")
            except (OSError, ValueError):
                pass
            
            # ì™¸ë¶€ ì—°ê²° í…ŒìŠ¤íŠ¸
            webhook_url = self.config.get('DISCORD_WEBHOOK_URL', '')
            if webhook_url:
                try:
                    response = requests.head(webhook_url, timeout=5)
                    if response.status_code == 200:
                        optimizations.append("ì™¸ë¶€ ì—°ê²° ìƒíƒœ ì–‘í˜¸")
                    else:
                        optimizations.append(f"ì™¸ë¶€ ì—°ê²° ì‘ë‹µ ì½”ë“œ: {response.status_code}")
                except requests.RequestException as e:
                    optimizations.append(f"ì™¸ë¶€ ì—°ê²° í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
            
            duration = time.time() - start_time
            
            result = {
                'status': 'SUCCESS',
                'before_value': established_count,
                'after_value': established_count,
                'improvement': 0,
                'details': '; '.join(optimizations) if optimizations else 'ìµœì í™” ì‘ì—… ì—†ìŒ',
                'duration': duration
            }
            
            logger.info(f"ë„¤íŠ¸ì›Œí¬ ìµœì í™” ì™„ë£Œ: {established_count}ê°œ ì—°ê²°")
            return result
            
        except Exception as e:
            logger.error(f"ë„¤íŠ¸ì›Œí¬ ìµœì í™” ì‹¤íŒ¨: {e}")
            return {
                'status': 'ERROR',
                'before_value': 0,
                'after_value': 0,
                'improvement': 0,
                'details': f"ì˜¤ë¥˜: {e}",
                'duration': time.time() - start_time
            }
    
    def optimize_cache(self):
        """ìºì‹œ ìµœì í™”"""
        start_time = time.time()
        
        try:
            optimizations = []
            
            # Python ëª¨ë“ˆ ìºì‹œ ì •ë¦¬
            cache_dirs = ['__pycache__', '.pytest_cache']
            removed_files = 0
            
            for root, dirs, files in os.walk('.'):
                for cache_dir in cache_dirs:
                    if cache_dir in dirs:
                        cache_path = os.path.join(root, cache_dir)
                        try:
                            import shutil
                            shutil.rmtree(cache_path)
                            removed_files += 1
                        except (OSError, PermissionError):
                            pass
            
            if removed_files > 0:
                optimizations.append(f"{removed_files}ê°œ ìºì‹œ ë””ë ‰í† ë¦¬ ì •ë¦¬")
            
            # ë¸Œë¼ìš°ì € ìºì‹œ ì •ë¦¬ (ì‚¬ìš©ì í™ˆ ë””ë ‰í† ë¦¬)
            try:
                home_dir = os.path.expanduser('~')
                browser_caches = [
                    '.cache/google-chrome',
                    '.cache/firefox',
                    '.cache/chromium'
                ]
                
                for cache_dir in browser_caches:
                    cache_path = os.path.join(home_dir, cache_dir)
                    if os.path.exists(cache_path):
                        try:
                            # ìºì‹œ í¬ê¸° í™•ì¸ (ì •ë¦¬í•˜ì§€ëŠ” ì•ŠìŒ, ì‚¬ìš©ì ë°ì´í„°ì´ë¯€ë¡œ)
                            cache_size = sum(
                                os.path.getsize(os.path.join(dirpath, filename))
                                for dirpath, dirnames, filenames in os.walk(cache_path)
                                for filename in filenames
                            )
                            if cache_size > 100 * 1024 * 1024:  # 100MB ì´ìƒ
                                optimizations.append(f"{cache_dir} ìºì‹œ í¬ê¸°: {cache_size/1024/1024:.1f}MB")
                        except (OSError, PermissionError):
                            pass
            except Exception:
                pass
            
            duration = time.time() - start_time
            
            result = {
                'status': 'SUCCESS',
                'before_value': 0,
                'after_value': 0,
                'improvement': removed_files,
                'details': '; '.join(optimizations) if optimizations else 'ìµœì í™” ì‘ì—… ì—†ìŒ',
                'duration': duration
            }
            
            logger.info(f"ìºì‹œ ìµœì í™” ì™„ë£Œ: {removed_files}ê°œ í•­ëª© ì •ë¦¬")
            return result
            
        except Exception as e:
            logger.error(f"ìºì‹œ ìµœì í™” ì‹¤íŒ¨: {e}")
            return {
                'status': 'ERROR',
                'before_value': 0,
                'after_value': 0,
                'improvement': 0,
                'details': f"ì˜¤ë¥˜: {e}",
                'duration': time.time() - start_time
            }
    
    def optimize_system_settings(self):
        """ì‹œìŠ¤í…œ ì„¤ì • ìµœì í™”"""
        start_time = time.time()
        
        try:
            optimizations = []
            
            # íŒŒì¼ ë””ìŠ¤í¬ë¦½í„° ì œí•œ í™•ì¸
            try:
                import resource
                soft, hard = resource.getrlimit(resource.RLIMIT_NOFILE)
                if soft < 4096:
                    optimizations.append(f"íŒŒì¼ ë””ìŠ¤í¬ë¦½í„° ì œí•œì´ ë‚®ìŠµë‹ˆë‹¤: {soft} (ê¶Œì¥: 4096+)")
                else:
                    optimizations.append(f"íŒŒì¼ ë””ìŠ¤í¬ë¦½í„° ì œí•œ ì ì ˆ: {soft}")
            except (ImportError, OSError):
                pass
            
            # ìŠ¤ì™‘ ì„¤ì • í™•ì¸
            swap = psutil.swap_memory()
            if swap.total == 0:
                optimizations.append("ìŠ¤ì™‘ì´ ì„¤ì •ë˜ì§€ ì•ŠìŒ (ê¶Œì¥: ì‹œìŠ¤í…œ ë©”ëª¨ë¦¬ì˜ 50-100%)")
            elif swap.total < psutil.virtual_memory().total * 0.5:
                optimizations.append(f"ìŠ¤ì™‘ í¬ê¸°ê°€ ì‘ìŠµë‹ˆë‹¤: {swap.total/1024/1024/1024:.1f}GB")
            else:
                optimizations.append(f"ìŠ¤ì™‘ ì„¤ì • ì ì ˆ: {swap.total/1024/1024/1024:.1f}GB")
            
            # ì‹œìŠ¤í…œ ë¡œë“œ í™•ì¸
            try:
                load_avg = os.getloadavg()
                cpu_count = psutil.cpu_count()
                if load_avg[0] > cpu_count:
                    optimizations.append(f"ì‹œìŠ¤í…œ ë¡œë“œê°€ ë†’ìŠµë‹ˆë‹¤: {load_avg[0]:.2f} (CPU: {cpu_count}ê°œ)")
                else:
                    optimizations.append(f"ì‹œìŠ¤í…œ ë¡œë“œ ì •ìƒ: {load_avg[0]:.2f}")
            except (OSError, AttributeError):
                pass
            
            # ë””ìŠ¤í¬ I/O ìŠ¤ì¼€ì¤„ëŸ¬ í™•ì¸ (Linux)
            try:
                if os.path.exists('/sys/block/sda/queue/scheduler'):
                    with open('/sys/block/sda/queue/scheduler', 'r') as f:
                        scheduler = f.read().strip()
                    optimizations.append(f"I/O ìŠ¤ì¼€ì¤„ëŸ¬: {scheduler}")
            except (OSError, PermissionError):
                pass
            
            duration = time.time() - start_time
            
            result = {
                'status': 'SUCCESS',
                'before_value': 0,
                'after_value': 0,
                'improvement': 0,
                'details': '; '.join(optimizations),
                'duration': duration
            }
            
            logger.info("ì‹œìŠ¤í…œ ì„¤ì • ìµœì í™” ì™„ë£Œ")
            return result
            
        except Exception as e:
            logger.error(f"ì‹œìŠ¤í…œ ì„¤ì • ìµœì í™” ì‹¤íŒ¨: {e}")
            return {
                'status': 'ERROR',
                'before_value': 0,
                'after_value': 0,
                'improvement': 0,
                'details': f"ì˜¤ë¥˜: {e}",
                'duration': time.time() - start_time
            }
    
    def save_optimization_result(self, task_type, result):
        """ìµœì í™” ê²°ê³¼ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            cursor.execute('''
                INSERT INTO optimization_tasks (
                    task_type, status, before_value, after_value,
                    improvement, details, duration
                ) VALUES (?, ?, ?, ?, ?, ?, ?)
            ''', (
                task_type,
                result['status'],
                result['before_value'],
                result['after_value'],
                result['improvement'],
                result['details'],
                result['duration']
            ))
            
            conn.commit()
            conn.close()
            
        except Exception as e:
            logger.error(f"ìµœì í™” ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: {e}")
    
    def run_optimization(self, task_types=None):
        """ìµœì í™” ì‹¤í–‰"""
        if task_types is None:
            task_types = list(self.optimization_tasks.keys())
        
        results = {}
        
        for task_type in task_types:
            if task_type in self.optimization_tasks:
                logger.info(f"{task_type} ìµœì í™” ì‹œì‘")
                try:
                    result = self.optimization_tasks[task_type]()
                    results[task_type] = result
                    self.save_optimization_result(task_type, result)
                    logger.info(f"{task_type} ìµœì í™” ì™„ë£Œ: {result['status']}")
                except Exception as e:
                    logger.error(f"{task_type} ìµœì í™” ì‹¤íŒ¨: {e}")
                    results[task_type] = {
                        'status': 'ERROR',
                        'before_value': 0,
                        'after_value': 0,
                        'improvement': 0,
                        'details': f"ì˜¤ë¥˜: {e}",
                        'duration': 0
                    }
        
        return results
    
    def start_monitoring(self, interval=60):
        """ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì‹œì‘"""
        self.running = True
        
        def monitor_loop():
            while self.running:
                try:
                    # ë©”íŠ¸ë¦­ ìˆ˜ì§‘
                    metrics = self.collect_system_metrics()
                    if metrics:
                        self.save_metrics(metrics)
                        
                        # ì„±ëŠ¥ ì´ìŠˆ ë¶„ì„
                        issues = self.analyze_performance_issues(metrics)
                        
                        # ì‹¬ê°í•œ ì´ìŠˆê°€ ìˆìœ¼ë©´ ìë™ ìµœì í™”
                        critical_issues = [i for i in issues if i['severity'] in ['HIGH', 'CRITICAL']]
                        if critical_issues:
                            logger.warning(f"{len(critical_issues)}ê°œ ì‹¬ê°í•œ ì„±ëŠ¥ ì´ìŠˆ ë°œê²¬")
                            
                            # ìë™ ìµœì í™” ì‹¤í–‰
                            auto_tasks = ['memory_cleanup', 'log_rotation']
                            self.run_optimization(auto_tasks)
                    
                    time.sleep(interval)
                    
                except Exception as e:
                    logger.error(f"ëª¨ë‹ˆí„°ë§ ì˜¤ë¥˜: {e}")
                    time.sleep(interval)
        
        self.monitor_thread = threading.Thread(target=monitor_loop, daemon=True)
        self.monitor_thread.start()
        logger.info(f"ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì‹œì‘ (ê°„ê²©: {interval}ì´ˆ)")
    
    def stop_monitoring(self):
        """ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì¤‘ì§€"""
        self.running = False
        if self.monitor_thread:
            self.monitor_thread.join(timeout=5)
        logger.info("ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì¤‘ì§€")
    
    def generate_optimization_report(self, results):
        """ìµœì í™” ë¦¬í¬íŠ¸ ìƒì„±"""
        total_tasks = len(results)
        successful_tasks = len([r for r in results.values() if r['status'] == 'SUCCESS'])
        total_improvement = sum(r['improvement'] for r in results.values() if r['improvement'] > 0)
        total_duration = sum(r['duration'] for r in results.values())
        
        report = {
            'timestamp': datetime.now().isoformat(),
            'summary': {
                'total_tasks': total_tasks,
                'successful_tasks': successful_tasks,
                'success_rate': (successful_tasks / total_tasks * 100) if total_tasks > 0 else 0,
                'total_improvement': total_improvement,
                'total_duration': total_duration
            },
            'detailed_results': results
        }
        
        return report
    
    def send_optimization_alert(self, report):
        """ìµœì í™” ì•Œë¦¼ ë°œì†¡"""
        try:
            webhook_url = self.config.get('DISCORD_WEBHOOK_URL')
            if not webhook_url:
                return
            
            success_rate = report['summary']['success_rate']
            total_tasks = report['summary']['total_tasks']
            successful_tasks = report['summary']['successful_tasks']
            
            # ì„±ê³µë¥ ì— ë”°ë¥¸ ìƒ‰ìƒ
            if success_rate >= 80:
                color = 0x2ecc71  # ì´ˆë¡ìƒ‰
                emoji = 'âœ…'
            elif success_rate >= 50:
                color = 0xf39c12  # ì£¼í™©ìƒ‰
                emoji = 'âš ï¸'
            else:
                color = 0xe74c3c  # ë¹¨ê°„ìƒ‰
                emoji = 'âŒ'
            
            embed = {
                'title': f"{emoji} ì‹œìŠ¤í…œ ìµœì í™” ì™„ë£Œ",
                'color': color,
                'fields': [
                    {
                        'name': 'ğŸ“Š ìµœì í™” ìš”ì•½',
                        'value': f"ì´ ì‘ì—…: {total_tasks}ê°œ\n"
                                f"ì„±ê³µ: {successful_tasks}ê°œ\n"
                                f"ì„±ê³µë¥ : {success_rate:.1f}%\n"
                                f"ì†Œìš”ì‹œê°„: {report['summary']['total_duration']:.1f}ì´ˆ",
                        'inline': True
                    }
                ],
                'timestamp': datetime.now().isoformat(),
                'footer': {
                    'text': 'í‹°ì¼“ ì•Œë¦¼ ì‹œìŠ¤í…œ ìµœì í™”'
                }
            }
            
            # ì£¼ìš” ê°œì„ ì‚¬í•­ ì¶”ê°€
            improvements = []
            for task_type, result in report['detailed_results'].items():
                if result['status'] == 'SUCCESS' and result['improvement'] > 0:
                    improvements.append(f"â€¢ {task_type}: {result['improvement']:+.1f}")
            
            if improvements:
                embed['fields'].append({
                    'name': 'ğŸš€ ì£¼ìš” ê°œì„ ì‚¬í•­',
                    'value': '\n'.join(improvements[:5]),
                    'inline': False
                })
            
            payload = {
                'embeds': [embed],
                'username': 'ì‹œìŠ¤í…œ ìµœì í™”ê¸°',
                'avatar_url': 'https://cdn-icons-png.flaticon.com/512/2920/2920277.png'
            }
            
            response = requests.post(
                webhook_url,
                json=payload,
                timeout=10
            )
            
            if response.status_code == 204:
                logger.info("ìµœì í™” ë¦¬í¬íŠ¸ ë°œì†¡ ì™„ë£Œ")
            else:
                logger.error(f"ìµœì í™” ë¦¬í¬íŠ¸ ë°œì†¡ ì‹¤íŒ¨: {response.status_code}")
                
        except Exception as e:
            logger.error(f"ìµœì í™” ì•Œë¦¼ ë°œì†¡ ì˜¤ë¥˜: {e}")

def signal_handler(signum, frame):
    """ì‹œê·¸ë„ í•¸ë“¤ëŸ¬"""
    logger.info("ì¢…ë£Œ ì‹ í˜¸ ìˆ˜ì‹ ")
    sys.exit(0)

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(description='í‹°ì¼“ ì•Œë¦¼ ì‹œìŠ¤í…œ ì„±ëŠ¥ ìµœì í™” ë„êµ¬')
    parser.add_argument('--config', '-c', default='config.json', help='ì„¤ì • íŒŒì¼ ê²½ë¡œ')
    parser.add_argument('--tasks', '-t', nargs='+', help='ì‹¤í–‰í•  ìµœì í™” ì‘ì—…')
    parser.add_argument('--monitor', '-m', action='store_true', help='ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì‹œì‘')
    parser.add_argument('--interval', '-i', type=int, default=60, help='ëª¨ë‹ˆí„°ë§ ê°„ê²© (ì´ˆ)')
    parser.add_argument('--report', '-r', action='store_true', help='ë¦¬í¬íŠ¸ ë°œì†¡')
    parser.add_argument('--output', '-o', help='ê²°ê³¼ë¥¼ íŒŒì¼ë¡œ ì €ì¥')
    parser.add_argument('--auto', '-a', action='store_true', help='ìë™ ìµœì í™” ëª¨ë“œ')
    parser.add_argument('--quiet', '-q', action='store_true', help='ì¡°ìš©í•œ ëª¨ë“œ')
    
    args = parser.parse_args()
    
    # ë¡œê·¸ ë””ë ‰í† ë¦¬ ìƒì„±
    os.makedirs('logs', exist_ok=True)
    
    if args.quiet:
        logging.getLogger().setLevel(logging.WARNING)
    
    # ì‹œê·¸ë„ í•¸ë“¤ëŸ¬ ë“±ë¡
    signal.signal(signal.SIGINT, signal_handler)
    signal.signal(signal.SIGTERM, signal_handler)
    
    # ìµœì í™”ê¸° ì´ˆê¸°í™”
    optimizer = SystemOptimizer(args.config)
    
    try:
        if args.monitor:
            # ëª¨ë‹ˆí„°ë§ ëª¨ë“œ
            optimizer.start_monitoring(args.interval)
            
            try:
                while True:
                    time.sleep(1)
            except KeyboardInterrupt:
                pass
            finally:
                optimizer.stop_monitoring()
        
        else:
            # ìµœì í™” ì‹¤í–‰
            if args.auto:
                # ìë™ ëª¨ë“œ: í˜„ì¬ ìƒíƒœë¥¼ ë¶„ì„í•˜ì—¬ í•„ìš”í•œ ìµœì í™”ë§Œ ì‹¤í–‰
                metrics = optimizer.collect_system_metrics()
                if metrics:
                    issues = optimizer.analyze_performance_issues(metrics)
                    
                    auto_tasks = []
                    for issue in issues:
                        if issue['type'] == 'memory_high':
                            auto_tasks.append('memory_cleanup')
                        elif issue['type'] == 'disk_high':
                            auto_tasks.extend(['disk_cleanup', 'log_rotation'])
                        elif issue['type'] == 'load_high':
                            auto_tasks.append('process_optimization')
                    
                    if auto_tasks:
                        results = optimizer.run_optimization(list(set(auto_tasks)))
                    else:
                        print("ìµœì í™”ê°€ í•„ìš”í•œ í•­ëª©ì´ ì—†ìŠµë‹ˆë‹¤.")
                        sys.exit(0)
                else:
                    print("ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­ì„ ìˆ˜ì§‘í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    sys.exit(1)
            else:
                # ìˆ˜ë™ ëª¨ë“œ
                results = optimizer.run_optimization(args.tasks)
            
            # ë¦¬í¬íŠ¸ ìƒì„±
            report = optimizer.generate_optimization_report(results)
            
            # ê²°ê³¼ ì¶œë ¥
            if not args.quiet:
                print(f"\n=== ìµœì í™” ê²°ê³¼ ===")
                print(f"ì´ ì‘ì—…: {report['summary']['total_tasks']}ê°œ")
                print(f"ì„±ê³µ: {report['summary']['successful_tasks']}ê°œ")
                print(f"ì„±ê³µë¥ : {report['summary']['success_rate']:.1f}%")
                print(f"ì†Œìš”ì‹œê°„: {report['summary']['total_duration']:.1f}ì´ˆ")
                
                for task_type, result in results.items():
                    status_emoji = 'âœ…' if result['status'] == 'SUCCESS' else 'âŒ'
                    print(f"  {status_emoji} {task_type}: {result['details']}")
            
            # íŒŒì¼ë¡œ ì €ì¥
            if args.output:
                with open(args.output, 'w', encoding='utf-8') as f:
                    json.dump(report, f, ensure_ascii=False, indent=2)
                print(f"ê²°ê³¼ê°€ {args.output}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤")
            
            # ë¦¬í¬íŠ¸ ë°œì†¡
            if args.report:
                optimizer.send_optimization_alert(report)
            
            # ì¢…ë£Œ ì½”ë“œ ì„¤ì •
            if report['summary']['success_rate'] < 50:
                sys.exit(1)
            else:
                sys.exit(0)
    
    except Exception as e:
        logger.error(f"ìµœì í™” ë„êµ¬ ì‹¤í–‰ ì˜¤ë¥˜: {e}")
        sys.exit(1)

if __name__ == '__main__':
    main()